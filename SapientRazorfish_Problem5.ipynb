{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Predicting Flight Delays:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get to know the problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary classification problem using mostly numerical predictators, except for one feature, UniqueCarrier is the categorical data. \n",
    "\n",
    "Here I built several different models to predict whether a flight will be canceled based on several factors.\n",
    "\n",
    "But I will start with logistic regression model, since our client want to know which airline (AA,UA, and DL) has the least risk of cancellation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Which airline has the least risk of cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the eight variables are very self-explanative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 Loading  the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Read data \n",
    "data = pd.read_csv(\"/users/janechou24/Python/exercise/CancelledFlights.csv\", names=['Canceled','Month','DepartureTime','UniqueCarrier','SchedElapsedTime','ArrDelay','DepDelay','Distance'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Summary statistics & looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Canceled        Month  DepartureTime  SchedElapsedTime     ArrDelay  \\\n",
      "count  6000.000000  6000.000000    6000.000000       6000.000000  6000.000000   \n",
      "mean      0.166667     6.220167    1330.466500        161.693500     8.113000   \n",
      "std       0.372709     3.436325     459.118234         78.064979    35.763134   \n",
      "min       0.000000     1.000000       5.000000         40.000000   -72.000000   \n",
      "25%       0.000000     3.000000     930.000000        105.000000    -8.000000   \n",
      "50%       0.000000     6.000000    1325.000000        145.000000     0.000000   \n",
      "75%       0.000000     9.000000    1715.000000        200.000000    10.000000   \n",
      "max       1.000000    12.000000    2359.000000        604.000000   410.000000   \n",
      "\n",
      "          DepDelay     Distance  \n",
      "count  6000.000000  6000.000000  \n",
      "mean      9.148833   987.588833  \n",
      "std      31.669299   646.666931  \n",
      "min     -16.000000    68.000000  \n",
      "25%      -3.000000   547.000000  \n",
      "50%       0.000000   837.000000  \n",
      "75%       6.000000  1249.000000  \n",
      "max     387.000000  4502.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "# summary the data\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Canceled  Month  DepartureTime UniqueCarrier  SchedElapsedTime  ArrDelay  \\\n",
      "0         1     12            814            UA               134         0   \n",
      "1         1     12            830            DL                90         0   \n",
      "2         1      1           1835            UA               213         0   \n",
      "3         1      4           1730            AA                80         0   \n",
      "4         1      7           1442            UA               103         0   \n",
      "\n",
      "   DepDelay  Distance  \n",
      "0         0       679  \n",
      "1         0       214  \n",
      "2         0      1605  \n",
      "3         0       235  \n",
      "4         0       413  \n"
     ]
    }
   ],
   "source": [
    "# And take a look of it \n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canceled</th>\n",
       "      <th>Month</th>\n",
       "      <th>DepartureTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>SchedElapsedTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Canceled  Month  DepartureTime  UniqueCarrier  SchedElapsedTime  \\\n",
       "0        False  False          False          False             False   \n",
       "1        False  False          False          False             False   \n",
       "2        False  False          False          False             False   \n",
       "3        False  False          False          False             False   \n",
       "4        False  False          False          False             False   \n",
       "5        False  False          False          False             False   \n",
       "6        False  False          False          False             False   \n",
       "7        False  False          False          False             False   \n",
       "8        False  False          False          False             False   \n",
       "9        False  False          False          False             False   \n",
       "10       False  False          False          False             False   \n",
       "11       False  False          False          False             False   \n",
       "12       False  False          False          False             False   \n",
       "13       False  False          False          False             False   \n",
       "14       False  False          False          False             False   \n",
       "15       False  False          False          False             False   \n",
       "16       False  False          False          False             False   \n",
       "17       False  False          False          False             False   \n",
       "18       False  False          False          False             False   \n",
       "19       False  False          False          False             False   \n",
       "20       False  False          False          False             False   \n",
       "21       False  False          False          False             False   \n",
       "22       False  False          False          False             False   \n",
       "23       False  False          False          False             False   \n",
       "24       False  False          False          False             False   \n",
       "25       False  False          False          False             False   \n",
       "26       False  False          False          False             False   \n",
       "27       False  False          False          False             False   \n",
       "28       False  False          False          False             False   \n",
       "29       False  False          False          False             False   \n",
       "...        ...    ...            ...            ...               ...   \n",
       "5970     False  False          False          False             False   \n",
       "5971     False  False          False          False             False   \n",
       "5972     False  False          False          False             False   \n",
       "5973     False  False          False          False             False   \n",
       "5974     False  False          False          False             False   \n",
       "5975     False  False          False          False             False   \n",
       "5976     False  False          False          False             False   \n",
       "5977     False  False          False          False             False   \n",
       "5978     False  False          False          False             False   \n",
       "5979     False  False          False          False             False   \n",
       "5980     False  False          False          False             False   \n",
       "5981     False  False          False          False             False   \n",
       "5982     False  False          False          False             False   \n",
       "5983     False  False          False          False             False   \n",
       "5984     False  False          False          False             False   \n",
       "5985     False  False          False          False             False   \n",
       "5986     False  False          False          False             False   \n",
       "5987     False  False          False          False             False   \n",
       "5988     False  False          False          False             False   \n",
       "5989     False  False          False          False             False   \n",
       "5990     False  False          False          False             False   \n",
       "5991     False  False          False          False             False   \n",
       "5992     False  False          False          False             False   \n",
       "5993     False  False          False          False             False   \n",
       "5994     False  False          False          False             False   \n",
       "5995     False  False          False          False             False   \n",
       "5996     False  False          False          False             False   \n",
       "5997     False  False          False          False             False   \n",
       "5998     False  False          False          False             False   \n",
       "5999     False  False          False          False             False   \n",
       "\n",
       "      ArrDelay  DepDelay  Distance  \n",
       "0        False     False     False  \n",
       "1        False     False     False  \n",
       "2        False     False     False  \n",
       "3        False     False     False  \n",
       "4        False     False     False  \n",
       "5        False     False     False  \n",
       "6        False     False     False  \n",
       "7        False     False     False  \n",
       "8        False     False     False  \n",
       "9        False     False     False  \n",
       "10       False     False     False  \n",
       "11       False     False     False  \n",
       "12       False     False     False  \n",
       "13       False     False     False  \n",
       "14       False     False     False  \n",
       "15       False     False     False  \n",
       "16       False     False     False  \n",
       "17       False     False     False  \n",
       "18       False     False     False  \n",
       "19       False     False     False  \n",
       "20       False     False     False  \n",
       "21       False     False     False  \n",
       "22       False     False     False  \n",
       "23       False     False     False  \n",
       "24       False     False     False  \n",
       "25       False     False     False  \n",
       "26       False     False     False  \n",
       "27       False     False     False  \n",
       "28       False     False     False  \n",
       "29       False     False     False  \n",
       "...        ...       ...       ...  \n",
       "5970     False     False     False  \n",
       "5971     False     False     False  \n",
       "5972     False     False     False  \n",
       "5973     False     False     False  \n",
       "5974     False     False     False  \n",
       "5975     False     False     False  \n",
       "5976     False     False     False  \n",
       "5977     False     False     False  \n",
       "5978     False     False     False  \n",
       "5979     False     False     False  \n",
       "5980     False     False     False  \n",
       "5981     False     False     False  \n",
       "5982     False     False     False  \n",
       "5983     False     False     False  \n",
       "5984     False     False     False  \n",
       "5985     False     False     False  \n",
       "5986     False     False     False  \n",
       "5987     False     False     False  \n",
       "5988     False     False     False  \n",
       "5989     False     False     False  \n",
       "5990     False     False     False  \n",
       "5991     False     False     False  \n",
       "5992     False     False     False  \n",
       "5993     False     False     False  \n",
       "5994     False     False     False  \n",
       "5995     False     False     False  \n",
       "5996     False     False     False  \n",
       "5997     False     False     False  \n",
       "5998     False     False     False  \n",
       "5999     False     False     False  \n",
       "\n",
       "[6000 rows x 8 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See whether existing missing values \n",
    "pd.isnull(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canceled              0.372709\n",
      "Month                 3.436325\n",
      "DepartureTime       459.118234\n",
      "SchedElapsedTime     78.064979\n",
      "ArrDelay             35.763134\n",
      "DepDelay             31.669299\n",
      "Distance            646.666931\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See the values' flutuation \n",
    "print (data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniqueCarrier    AA    DL    UA\n",
      "Canceled                       \n",
      "0              1983  1499  1518\n",
      "1               493   189   318\n"
     ]
    }
   ],
   "source": [
    "# To have a traditional probability perspective answer for the question: \n",
    "\n",
    "import pandas as pd\n",
    "print(pd.crosstab(data['Canceled'], data['UniqueCarrier'], rownames=['Canceled']))\n",
    "\n",
    "Cancellratio_AA = 493/(1983+493)\n",
    "Cancellratio_DL = 189/(1499+189)\n",
    "Cancellratio_UA = 318/(1518+318)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1991114701130856\n"
     ]
    }
   ],
   "source": [
    "print(Cancellratio_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11196682464454977\n"
     ]
    }
   ],
   "source": [
    "print(Cancellratio_DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17320261437908496\n"
     ]
    }
   ],
   "source": [
    "print(Cancellratio_UA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we could conclude that from our existing dataset, the cancellation ratio of Airline DL is the lowest, however, this approach is biased by our dataset, therefore, the final answer would be provided by the log-ratio of the logistic model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEICAYAAAAOW7ATAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bdec748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data.hist()\n",
    "pl.subplots_adjust(left=0.08, right=0.95, wspace=1, hspace=1)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see our dataset is not very balanced, there are much less cancellation cases than non-cancellation, therefore, in our model evalution, we need compare our prediction with guessing non-cancellation all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAFRCAYAAAARoygwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12be694a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the ArrDelay and DepDelay are correlated with each other, and it is in our common sense, if the flight departs late, it is highly possibly it will also arrive late. Therefore, if our future modelling didn't perform well, we may work on getting rid of one of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4  Dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, to deal with the categorical preditor, I used a dummy coding to transfer it from sting to numerical, and it is in line with the logistica model, thus we could interprete it afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Carrier_AA  Carrier_DL  Carrier_UA\n",
      "0           0           0           1\n",
      "1           0           1           0\n",
      "2           0           0           1\n",
      "3           1           0           0\n",
      "4           0           0           1\n"
     ]
    }
   ],
   "source": [
    "dummy_ranks = pd.get_dummies(data['UniqueCarrier'], prefix='Carrier')\n",
    "print(dummy_ranks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Canceled  Month  DepartureTime  SchedElapsedTime  ArrDelay  DepDelay  \\\n",
      "0         1     12            814               134         0         0   \n",
      "1         1     12            830                90         0         0   \n",
      "2         1      1           1835               213         0         0   \n",
      "3         1      4           1730                80         0         0   \n",
      "4         1      7           1442               103         0         0   \n",
      "\n",
      "   Distance  Carrier_DL  Carrier_UA  intercept  \n",
      "0       679           0           1        1.0  \n",
      "1       214           1           0        1.0  \n",
      "2      1605           0           1        1.0  \n",
      "3       235           0           0        1.0  \n",
      "4       413           0           1        1.0  \n"
     ]
    }
   ],
   "source": [
    "# Here I include the intercept as the Carrier_AA. \n",
    "cols_to_keep = ['Canceled','Month','DepartureTime','SchedElapsedTime','ArrDelay',\n",
    "                'DepDelay', 'Distance']\n",
    "    \n",
    "logdata = data[cols_to_keep].join(dummy_ranks.loc[:, ['Carrier_DL','Carrier_UA']])\n",
    "logdata['intercept'] = 1.0\n",
    "print (logdata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5  Performing the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408349\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "train_cols = logdata.columns[1:]\n",
    "# Index([gre, gpa, prestige_2, prestige_3, prestige_4], dtype=object)\n",
    "\n",
    "logit = sm.Logit(logdata['Canceled'], logdata[train_cols])\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6  Interpreting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Canceled   No. Observations:                 6000\n",
      "Model:                          Logit   Df Residuals:                     5991\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Sun, 26 Nov 2017   Pseudo R-squ.:                 0.09369\n",
      "Time:                        14:44:40   Log-Likelihood:                -2450.1\n",
      "converged:                       True   LL-Null:                       -2703.4\n",
      "                                        LLR p-value:                2.772e-104\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Month               -0.1159      0.011    -10.638      0.000      -0.137      -0.095\n",
      "DepartureTime        0.0003   8.01e-05      3.306      0.001       0.000       0.000\n",
      "SchedElapsedTime     0.0184      0.003      6.960      0.000       0.013       0.024\n",
      "ArrDelay             0.0054      0.002      2.308      0.021       0.001       0.010\n",
      "DepDelay            -0.0462      0.005    -10.064      0.000      -0.055      -0.037\n",
      "Distance            -0.0027      0.000     -8.058      0.000      -0.003      -0.002\n",
      "Carrier_DL          -0.8847      0.097     -9.149      0.000      -1.074      -0.695\n",
      "Carrier_UA          -0.1773      0.083     -2.130      0.033      -0.340      -0.014\n",
      "intercept           -1.2545      0.181     -6.934      0.000      -1.609      -0.900\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the exponential of each of the coefficients to generate the odds ratios. This tells you how a 1 unit increase or decrease in a variable affects the odds of being cancelled. \n",
    "\n",
    "The odds equals the ratio between the probability of an event and  the probability of a non-event. Here our event is flight cancellation. And the odds ratio is the ratio between two cases'odds.\n",
    "\n",
    "\n",
    "For example, we can expect as an odds ratio less than 1 implies a negative relationship,larger than 1 implies postive relationship. Here intercept, i.e. Carrier_AA has the least odds ratio, which means the odds of carrier_AA being cancelled is 0.28 times of the odds of other two carrier being cancelled. \n",
    "\n",
    "Therefore, we could advise our customers that AA airline, has the least odds, or put it another way, has the least probability of cancelation, i.e. the least risk of cancellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month               0.890554\n",
      "DepartureTime       1.000265\n",
      "SchedElapsedTime    1.018618\n",
      "ArrDelay            1.005430\n",
      "DepDelay            0.954870\n",
      "Distance            0.997308\n",
      "Carrier_DL          0.412851\n",
      "Carrier_UA          0.837520\n",
      "intercept           0.285230\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the odds ratio. \n",
    "print (np.exp(result.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7  Predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I wrote a function using logistic model output to predict whether a flight will be canceled. In this case, you need to have the predictors values ready and then you could call the function, it will return to a proability of being cancelled based on the input.\n",
    "\n",
    "Normally, we use 0.5 as a threhold for the classfication, if the proability is less than 0.5, we could predict it will not be cancelled based on the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.08941043e-230])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[12,800,134,0,0,0,600,0,0]\n",
    "\n",
    "def predict_cancel_log(x):\n",
    "    y_pred = result.predict(x)\n",
    "    return(y_pred)\n",
    "\n",
    "predict_cancel_log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3 . More prediction models \n",
    "Here I will use other machine learning methods like neural network, K-NN, etc. to do the prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Neural network \n",
    "\n",
    "\n",
    "#### 3.1.1 Encoding categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canceled</th>\n",
       "      <th>Month</th>\n",
       "      <th>DepartureTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>SchedElapsedTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>814</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1835</td>\n",
       "      <td>2</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1730</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1442</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Canceled  Month  DepartureTime  UniqueCarrier  SchedElapsedTime  ArrDelay  \\\n",
       "0         1     12            814              2               134         0   \n",
       "1         1     12            830              1                90         0   \n",
       "2         1      1           1835              2               213         0   \n",
       "3         1      4           1730              0                80         0   \n",
       "4         1      7           1442              2               103         0   \n",
       "\n",
       "   DepDelay  Distance  \n",
       "0         0       679  \n",
       "1         0       214  \n",
       "2         0      1605  \n",
       "3         0       235  \n",
       "4         0       413  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['UniqueCarrier'] = encoder.fit_transform(data['UniqueCarrier'].astype('str'))\n",
    "\n",
    "# AA:0, DL:1, UA:2\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2  Feature extraction and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If dealing with unstructured data like text or image, we first need extract numerical features from data, here I could only do the feature selection part, it's a trial and error process, to begin with, I tried with the whole features provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3  Time to get to the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the data \n",
    "# X = data.loc[:,['Month','DepartureTime','UniqueCarrier','SchedElapsedTime','ArrDelay',' DepDelay', 'Distance']]\n",
    "# y = data.loc[:,'Canceled']\n",
    "# Specify the target labels and flatten the array\n",
    "X = data.ix[:,1:8]\n",
    "y = np.ravel(data.Canceled)\n",
    "\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the train set\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Dense(8, activation='relu', input_shape=(7,)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4  Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.27024132,  0.44427234, -0.3544026 , -0.04719263,  0.07320273,\n",
       "          0.60442156,  0.44087499,  0.33532733],\n",
       "        [ 0.33530182, -0.3213338 ,  0.01171237,  0.45314068,  0.0979048 ,\n",
       "          0.62229222,  0.44626969, -0.22074386],\n",
       "        [ 0.51410717, -0.29249054,  0.35965592,  0.26467764, -0.39673543,\n",
       "         -0.58547187,  0.18905735,  0.10271639],\n",
       "        [-0.54689115,  0.40789789, -0.59163904, -0.21388069,  0.1132496 ,\n",
       "         -0.22547728,  0.5441851 ,  0.26034153],\n",
       "        [-0.61801988,  0.42736715,  0.30368811, -0.00454342,  0.48824567,\n",
       "         -0.17185077, -0.36817494, -0.38221249],\n",
       "        [ 0.60518414, -0.11153978, -0.08666319,  0.21750414, -0.57183528,\n",
       "         -0.39851463, -0.52662295,  0.03010041],\n",
       "        [-0.13790873, -0.55722576, -0.34223723,  0.1035071 ,  0.4770599 ,\n",
       "         -0.24313921,  0.55417424,  0.35044032]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[-0.47457457, -0.49574658,  0.09515452, -0.45104635,  0.13330793,\n",
       "          0.51392061,  0.5861581 ,  0.17459351],\n",
       "        [ 0.60936254, -0.32768705,  0.49925095, -0.26594442,  0.28619301,\n",
       "          0.36040092, -0.50133961,  0.44649237],\n",
       "        [-0.31470129, -0.58124095,  0.30694968, -0.49005824,  0.29671323,\n",
       "          0.31232178, -0.44504499, -0.11072862],\n",
       "        [-0.08747649,  0.22940898,  0.03074545,  0.39211446, -0.0428434 ,\n",
       "          0.23264176,  0.16345906,  0.41043562],\n",
       "        [ 0.24646205, -0.27775604, -0.55471772,  0.29533017,  0.04626244,\n",
       "          0.06547022, -0.21932587,  0.18385434],\n",
       "        [-0.45646298, -0.4794656 , -0.13481   ,  0.60188526, -0.42483318,\n",
       "         -0.43949839, -0.03097087,  0.15591913],\n",
       "        [ 0.49046928,  0.07936114, -0.58555341,  0.12956345, -0.15669817,\n",
       "         -0.15509334,  0.45932239, -0.51327926],\n",
       "        [ 0.06793642, -0.30632639, -0.08429801,  0.22041637, -0.09341156,\n",
       "          0.48165327,  0.60349518,  0.26061714]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[ 0.36790061],\n",
       "        [-0.8096813 ],\n",
       "        [ 0.3053714 ],\n",
       "        [ 0.05658859],\n",
       "        [ 0.75308764],\n",
       "        [-0.73147792],\n",
       "        [-0.22040111],\n",
       "        [ 0.11312699]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.4207 - acc: 0.8376\n",
      "Epoch 2/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.3613 - acc: 0.8403\n",
      "Epoch 3/20\n",
      "4020/4020 [==============================] - 9s 2ms/step - loss: 0.2863 - acc: 0.8510\n",
      "Epoch 4/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.1925 - acc: 0.9286\n",
      "Epoch 5/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.1358 - acc: 0.9585\n",
      "Epoch 6/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.1073 - acc: 0.9662\n",
      "Epoch 7/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0928 - acc: 0.9709\n",
      "Epoch 8/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.0855 - acc: 0.9724\n",
      "Epoch 9/20\n",
      "4020/4020 [==============================] - 9s 2ms/step - loss: 0.0790 - acc: 0.9746\n",
      "Epoch 10/20\n",
      "4020/4020 [==============================] - 10s 2ms/step - loss: 0.0741 - acc: 0.9781\n",
      "Epoch 11/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0708 - acc: 0.9779\n",
      "Epoch 12/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0695 - acc: 0.9811\n",
      "Epoch 13/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0700 - acc: 0.9808\n",
      "Epoch 14/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0665 - acc: 0.9823\n",
      "Epoch 15/20\n",
      "4020/4020 [==============================] - 10s 3ms/step - loss: 0.0671 - acc: 0.9811\n",
      "Epoch 16/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0657 - acc: 0.9803\n",
      "Epoch 17/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0685 - acc: 0.9811\n",
      "Epoch 18/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0664 - acc: 0.9811\n",
      "Epoch 19/20\n",
      "4020/4020 [==============================] - 11s 3ms/step - loss: 0.0674 - acc: 0.9816\n",
      "Epoch 20/20\n",
      "4020/4020 [==============================] - 10s 3ms/step - loss: 0.0644 - acc: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bce2fd0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train,epochs=20, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5  Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980/1980 [==============================] - 0s 41us/step\n",
      "[0.16914608288895, 0.93131313155395812]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is a list that holds the combination of the loss and the accuracy. In this case, you see that both seem very great. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.6  How to run the model by calling function \n",
    "In this neural network, since I used a sigmoid activation function for the output, so the output would be the probability of cancellation, and we could choose 0.5 as the threhold as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95814508]], dtype=float32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example, a new observation is:\n",
    "X_new = [[12,830,2,90,0,0,214]]\n",
    "\n",
    "\n",
    "def predict_cancel_neural(X):\n",
    "    X_newstandard = scaler.transform(X)\n",
    "    y_pred = model.predict(X_newstandard)\n",
    "    return y_pred\n",
    "# Here we predict it will be cancelled in this input.\n",
    "predict_cancel_neural(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Naive_bayes\n",
    "#### 3.2.1  Bernoulli\n",
    "You could call the predict_cancel_BernoulliNB function on new data and it will return to 0 or 1, representing not cancel or cancel, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, y)\n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "def predict_cancel_BernoulliNB(X): \n",
    "    y_pred = clf.predict(X)\n",
    "    return y_pred\n",
    "\n",
    "predict_cancel_BernoulliNB(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 6000 points : 141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X, y).predict(X)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" \n",
    "      % (data.shape[0],(y != y_pred).sum()))\n",
    "\n",
    "def predict_cancel_GaussianNB(X_new): \n",
    "    y_pred = gnb.fit(X, y).predict(X_new)\n",
    "    return y_pred\n",
    "\n",
    "predict_cancel_GaussianNB(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2  instantiate a K-NN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 2. instantiate the model (with the default parameters)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# In order to make a prediction, \n",
    "# the new observation must have the same features as the training observations, both in number and meaning.\n",
    "\n",
    "# 3. fit the model with data (occurs in-place)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# 4. predict the response for a new observation\n",
    "# here you pass in 4 features, the number of features that have been learned\n",
    "knn.predict(X_new)\n",
    "\n",
    "\n",
    "def predict_cancel_KNN(X_new): \n",
    "    y_pred = knn.predict(X_new)\n",
    "    return y_pred\n",
    "\n",
    "predict_cancel_KNN(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Final conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To predict whether a flight will be canceled.The user could use all the above method including logistic regression,  neural network, different naive bayes, and k-nn functions to get the prediction, then determine the final answer with the majority of the output of the models.\n",
    "\n",
    "\n",
    "\n",
    "For example: in this case, with the X_new[12, 830, 2, 90, 0, 0, 214], only Bernoulli naive bayes predict would be non-cancellation, but others all think it would be cancelled, so we predict this case be cancelled. You can expand this analysis to many other new inputs as well.\n",
    "\n",
    "\n",
    "And for the dataset provided, I will suggest that AA airline has the least risk of cancellation comparing with other two. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
